"""Text normalization utilities for consistent processing."""

import re
import unicodedata


def _extract_code_blocks(text: str) -> tuple[str, list[str]]:
    """Extract code blocks and replace with placeholders.

    Args:
        text: Text containing code blocks

    Returns:
        Tuple of (text with placeholders, list of extracted code blocks)
    """
    code_blocks = []
    placeholder_base = "\x00CODE_BLOCK_{}\x00"

    # Match fenced code blocks (```)
    def replace_fenced(match):
        code_blocks.append(match.group(0))
        return placeholder_base.format(len(code_blocks) - 1)

    # Match fenced code blocks with optional language identifier
    text = re.sub(r"```[^\n]*\n.*?```", replace_fenced, text, flags=re.DOTALL)

    # Match inline code (`)
    def replace_inline(match):
        code_blocks.append(match.group(0))
        return placeholder_base.format(len(code_blocks) - 1)

    text = re.sub(r"`[^`\n]+`", replace_inline, text)

    return text, code_blocks


def _restore_code_blocks(text: str, code_blocks: list[str]) -> str:
    """Restore code blocks from placeholders.

    Args:
        text: Text with placeholders
        code_blocks: List of original code blocks

    Returns:
        Text with code blocks restored
    """
    for i, block in enumerate(code_blocks):
        placeholder = f"\x00CODE_BLOCK_{i}\x00"
        text = text.replace(placeholder, block)
    return text


def normalize_text(text: str) -> str:
    """Normalize text by cleaning whitespace, newlines, and escaped characters.

    Normalization steps:
    1. Extract code blocks (preserve them from normalization)
    2. Normalize Unicode characters (NFC form)
    3. Replace multiple consecutive spaces with single space
    4. Replace lines with only whitespace with empty lines
    5. Replace multiple consecutive newlines with double newline
    6. Unescape markdown characters: \\*\\* -> **, smart quotes -> regular quotes
    7. Unescape characters in headings: \\. -> ., \\[ -> [, \\] -> ]
    8. Strip leading/trailing whitespace
    9. Restore code blocks

    Args:
        text: Raw text content

    Returns:
        Normalized text string
    """
    if not text:
        return text

    # Extract code blocks to preserve them
    text, code_blocks = _extract_code_blocks(text)

    # Normalize Unicode to NFC form
    text = unicodedata.normalize("NFC", text)

    # Replace multiple spaces with single space
    text = re.sub(r" +", " ", text)

    # Replace lines with only whitespace with empty lines
    # This handles \n \n patterns (lines with only spaces)
    # Apply repeatedly to handle consecutive whitespace-only lines
    while True:
        new_text = re.sub(r"\n[ \t]+\n", "\n\n", text)
        if new_text == text:
            break
        text = new_text

    # Replace multiple newlines with double newline
    text = re.sub(r"\n\n+", "\n\n", text)

    # Unescape markdown bold/italic markers
    text = text.replace("\\*\\*", "**")

    # Normalize smart quotes to regular quotes
    text = text.replace('"', '"')
    text = text.replace('"', '"')

    # Unescape characters in headings only
    # Pattern: line starting with # followed by escaped characters
    # \. -> . (escaped period after number in headings)
    text = re.sub(r"^(#{1,6}[^\n]*?)\\\.", r"\1.", text, flags=re.MULTILINE)
    # \[ -> [ (escaped bracket in headings)
    text = re.sub(r"^(#{1,6}[^\n]*?)\\\[", r"\1[", text, flags=re.MULTILINE)
    # \] -> ] (escaped bracket in headings)
    text = re.sub(r"^(#{1,6}[^\n]*?)\\\]", r"\1]", text, flags=re.MULTILINE)

    # Strip leading/trailing whitespace
    text = text.strip()

    # Restore code blocks
    text = _restore_code_blocks(text, code_blocks)

    return text


def clean_gemini_assistant(text: str) -> str:
    """Clean Gemini-specific artifacts from assistant responses.

    Removes:
    - "ìƒê°í•˜ëŠ” ê³¼ì • í‘œì‹œ" at the beginning
    - "Sheetsë¡œ ë‚´ë³´ë‚´ê¸°" after tables
    - "ì½”ë“œ ìŠ¤ë‹ˆí«" before code blocks
    - "ì†ŒìŠ¤" at the end

    Args:
        text: Raw assistant response text from Gemini

    Returns:
        Cleaned text
    """
    if not text:
        return text

    # Remove "ìƒê°í•˜ëŠ” ê³¼ì • í‘œì‹œ" at the beginning
    text = re.sub(r"^ìƒê°í•˜ëŠ” ê³¼ì • í‘œì‹œ\s*\n+", "", text)

    # Remove "Sheetsë¡œ ë‚´ë³´ë‚´ê¸°" after tables (standalone line)
    text = re.sub(r"\n+Sheetsë¡œ ë‚´ë³´ë‚´ê¸°\s*\n*", "\n", text)

    # Remove "ì½”ë“œ ìŠ¤ë‹ˆí«" before code blocks (standalone line)
    text = re.sub(r"\n*ì½”ë“œ ìŠ¤ë‹ˆí«\s*\n+", "\n\n", text)

    # Remove "ì†ŒìŠ¤" at the end
    text = re.sub(r"\n+ì†ŒìŠ¤\s*$", "", text)

    return text


def clean_grok_assistant(text: str) -> str:
    """Clean Grok-specific artifacts from assistant responses.

    Removes:
    - "Nsë™ì•ˆ ìƒê°í•¨" at the beginning (thinking time indicator)
    - Favicon images and web page count footer at the end

    Args:
        text: Raw assistant response text from Grok

    Returns:
        Cleaned text
    """
    if not text:
        return text

    # Remove "Nsë™ì•ˆ ìƒê°í•¨" at the beginning (e.g., "27së™ì•ˆ ìƒê°í•¨", "5së™ì•ˆ ìƒê°í•¨")
    text = re.sub(r"^\d+së™ì•ˆ ìƒê°í•¨\s*\n+", "", text)

    # Remove favicon images and web page count footer at the end
    # Pattern: multiple lines of ![](url) followed by "Nê°œì˜ ì›¹í˜ì´ì§€" text
    # This handles both simple and complex patterns:
    # - Simple: images + "1ê°œì˜ ì›¹í˜ì´ì§€ 31ê°œì˜ ì›¹í˜ì´ì§€"
    # - Complex: images + "ğ• ê²Œì‹œë¬¼ Nê°œ" + more images + "Nê°œì˜ ì›¹í˜ì´ì§€"
    pattern = r"(\n*!\[\]\([^\)]+\)\s*)+(\n*ğ• ê²Œì‹œë¬¼[^\n]*)?(\n*!\[\]\([^\)]+\)\s*)*\n*\d+ê°œì˜ ì›¹í˜ì´ì§€[^\n]*$"
    text = re.sub(pattern, "", text, flags=re.DOTALL)

    return text
